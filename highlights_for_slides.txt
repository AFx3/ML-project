___KERAS-ML-CUP___
Elasticnet > Lasso > Ridge

___Gridsearch parameters range___
- Learning rate: range(0.01, 0.4, 0.02)
- Momentum: range(0.4, 0.9, 0.1)
- Lambda1 (Lasso & Ridge): range(0.0001, 0.001, 0.0002)
- Lambda2 (ElasticNet): range(0.0001, 0.001, 0.0002)

___Fixed parameters___
- Batch size: 50
- EarlyStopping patience: 10
- Initialization: Glorot Normal (Normalizer Xavier)
- Activation function: hyperbolic tangent for hidden layer, linear for output layer

Results with 5 units 2 layers and EarlyStopping:

→→→ Regularizer: ElasticNet ←←←
Parameters:
- Learning rate: 0.02
- Momentum: 0.9
- Lmb1: 0.0005
- Lmb2: 0.0005
- Epochs: 30 ca

TR Loss:  8.474767684936523
VL Loss:  9.217187881469727
TS Loss:  9.190364972131503
------------------------------------------------
→→→ Optimizer: Adam ←←←
Parameters:
- Learning rate: 0.02
- Lmb1: 0.0007
- Lmb2: 0.0006
- Epochs: 35 ca

TR Loss:  9.503718376159668
VL Loss:  9.77015209197998
TS Loss:  8.887433316628265
------------------------------------------------
→→→ Regularizer: Lasso ←←←
Parameters:
- Learning rate: 0.02
- Momentum: 0.9
- Lmb: 0.0007
- Epochs: 35 ca

TR Loss:  8.725552558898926
VL Loss:  8.762089729309082
TS Loss:  8.616841958558712
------------------------------------------------
→→→ Regularizer: Ridge ←←←
Parameters:
- Learning rate: 0.02
- Momentum: 0.9
- Lmb: 0.0007
- Epochs: 35 ca

TR Loss:  9.8570556640625
VL Loss:  9.902321815490723
TS Loss:  9.872679336840495
------------------------------------------------

Results with 20 units 3 layers and EarlyStopping:

→→→ Regularizer: ElasticNet ←←←
Parameters:
- Learning rate: 0.02
- Momentum: 0.9
- Lmb1: 0.0005
- Lmb2: 0.0005
- Regularizer: ElasticNet
- Epochs: 25 ca

TR Loss:  3.864628791809082
VL Loss:  3.807034730911255
TS Loss:  3.4471385353443633
------------------------------------------------
→→→ Optimizer: Adam ←←←
Parameters:
- Learning rate: 0.02
- Lmb1: 0.0002
- Lmb2: 0.0003
- Epochs: 20 ca

TR Loss:  4.59597110748291
VL Loss:  4.700719356536865
TS Loss:  4.403369466999946
------------------------------------------------
→→→ Regularizer: Lasso ←←←
Parameters:
- Learning rate: 0.02
- Momentum: 0.9
- Lmb: 0.0005
- Epochs: 25 ca

TR Loss:  4.184088706970215
VL Loss:  4.157263278961182
TS Loss:  3.976973012638843
------------------------------------------------
→→→ Regularizer: Ridge ←←←
Parameters:
- Learning rate: 0.02
- Momentum: 0.9
- Lmb: 0.0005
- Epochs: 20 ca

TR Loss:  4.843702793121338
VL Loss:  5.259703636169434
TS Loss:  4.901579064855656
------------------------------------------------

ELM results with 300 hidden units and sigmoid activation function
- Activation function: sigmoid
- Weight initializer: Normalized Xavier

Train time: 0.3022739887237549
train loss: 0.366960
train acc: 0.997647
val loss: 0.838438
val acc: 0.986667
